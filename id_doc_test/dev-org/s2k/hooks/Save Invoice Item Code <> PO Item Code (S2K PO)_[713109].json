{
  "id": 713109,
  "type": "function",
  "name": "Save Invoice Item Code <> PO Item Code (S2K PO)",
  "url": "https://us.api.rossum.ai/v1/hooks/713109",
  "description": "",
  "settings": {
    "keep_first": true,
    "fields_to_db": [
      "item_order_id_match as po_item_code",
      "item_code_normalized as invoice_item_code",
      "selected_vendor_id as vendor_id",
      "item_description"
    ],
    "collection_name": "associations_s2k_item_codes",
    "normalize_array": "line_items",
    "skip_record_insert": [
      {
        "item_order_id_match": ""
      }
    ],
    "unique_natural_key": [
      "item_order_id_match",
      "item_code_normalized",
      "selected_vendor_id"
    ]
  },
  "active": true,
  "events": [
    "annotation_status.changed"
  ],
  "queues": [
    "https://us.api.rossum.ai/v1/queues/1771791"
  ],
  "run_after": [],
  "metadata": {},
  "config": {
    "schedule": {
      "cron": ""
    },
    "app": null,
    "payload_logging_enabled": false,
    "timeout_s": 30,
    "max_polling_time_s": 300,
    "retry_count": 4,
    "retry_after_polling_failure": true,
    "runtime": "python3.12",
    "code": "import copy\nimport json\nimport re\nfrom datetime import datetime\n\nimport requests\n\n\ndef rossum_hook_request_handler(payload):\n    \"\"\"\n    The rossum_hook_request_handler is an obligatory main function that accepts\n    input and produces output of the rossum custom function hook.\n    :param payload: see https://api.elis.rossum.ai/docs/#annotation-content-event-data-format\n    :return: messages and operations that update the annotation content or show messages\n    \"\"\"\n    messages = []\n    operations = []\n\n    if (\n        payload[\"event\"] == \"annotation_status\"\n        and payload[\"action\"] in (\"changed\")\n        and payload[\"annotation\"][\"status\"] in (\"confirmed\", \"exported\", \"failed_export\")\n    ):\n        try:\n            messages, operations = main(payload)\n        except Exception as msg:\n            messages = [create_message(\"error\", str(msg), None)]\n\n    return {\"messages\": messages, \"operations\": operations}\n\n\ndef main(payload):\n    messages = []\n    operations = []\n\n    # init variables\n    token = payload[\"rossum_authorization_token\"]\n    settings = payload[\"settings\"]\n    fields_to_db = payload[\"settings\"][\"fields_to_db\"]\n    fields_to_db, aliases = get_aliases(fields_to_db)\n    base_url = payload[\"base_url\"]\n    collection_name = settings[\"collection_name\"]\n    ds_url = f\"{base_url}/svc/data-storage/api/v1\"\n\n    # get content and schema\n    header = {\"Authorization\": f\"Bearer {token}\"}\n    res = requests.get(payload[\"annotation\"][\"content\"], headers=header, timeout=20)\n    content = json.loads(res.text)[\"content\"]\n    schema = payload[\"schemas\"][0][\"content\"]\n\n    # reformat annotation content for easier use\n    document = [normalize_annotation(content, {}, [], False, schema, fields_to_db)]\n    # normalize line items if needed\n    if settings.get(\"normalize_array\"):\n        document = normalize_arrays(document, settings[\"normalize_array\"])\n\n    # cleanup documents if there are docs to be excluded\n    included_documents = list()\n    if settings.get(\"skip_record_insert\"):\n        for excl_key_values in settings.get(\"skip_record_insert\"):\n            for doc in document:\n                print(doc)\n                exclude_doc = True\n                for key in excl_key_values:\n                    if excl_key_values[key] != doc.get(key):\n                        exclude_doc = False\n                        break\n                if not exclude_doc:\n                    included_documents.append(doc)\n    else:\n        included_documents = document\n\n    # run DS operations\n    if included_documents:\n        skip_insert = False\n        if settings.get(\"unique_natural_key\") and settings.get(\"primary_key\"):\n            skip_insert = remove_existing_objects(\n                included_documents,\n                collection_name,\n                settings[\"unique_natural_key\"],\n                settings[\"primary_key\"],\n                settings.get(\"keep_first\", False),\n                token,\n                ds_url,\n            )\n        # find record with the same annotation_id, if it exists\n        if not skip_insert:\n            response = find_in_data_storage_collection(\n                collection_name, {\"annotation_id\": payload[\"annotation\"][\"id\"]}, token, ds_url, {}\n            )\n            messages = process_data(\n                payload, response, included_documents, token, messages, aliases, collection_name, ds_url\n            )\n\n    return messages, operations\n\n\ndef process_data(payload, response, document, token, messages, aliases, collection_name, ds_url):\n    if not response[\"result\"]:\n        messages = create_record_in_ds(messages, payload, document, token, aliases, collection_name, ds_url)\n\n    elif response[\"result\"]:  # there is record with the same annotation id already\n        delete_many_data_storage_collection(\n            collection_name, {\"annotation_id\": payload[\"annotation\"][\"id\"]}, token, ds_url\n        )\n        messages = create_record_in_ds(messages, payload, document, token, aliases, collection_name, ds_url)\n\n    return messages\n\n\ndef replace_aliases(document, aliases):\n    for alias in aliases.keys():\n        if alias in document:\n            document[aliases[alias]] = document[alias]\n            del document[alias]\n    return document\n\n\ndef get_aliases(fields_to_db: dict):\n    aliases = {}\n    fields_to_db_n = []\n    for ftdb in fields_to_db:\n        parts = ftdb.split(\" as \")\n        if len(parts) > 1:\n            fields_to_db_n.append(parts[0])\n            aliases[parts[0]] = parts[1]\n        else:\n            fields_to_db_n.append(parts[0])\n    return fields_to_db_n, aliases\n\n\ndef normalize_arrays(document, array_name):\n    document = document[0]\n    objects = []\n    doc_without_array = copy.deepcopy(document)\n    del doc_without_array[array_name]\n    array = document.get(array_name)\n    if array:\n        for array_item in array:\n            tmp = copy.deepcopy(doc_without_array)\n            tmp.update(array_item)\n            objects.append(tmp)\n\n    return objects\n\n\ndef normalize_annotation(\n    content: dict,\n    accumulator: dict,\n    path: dict,\n    was_multivalue: bool,\n    schema: dict,\n    fields_to_db: list,\n) -> dict:\n\n    for index, node in enumerate(content):\n        if was_multivalue:\n            path.append(node[\"schema_id\"] + \"[\" + str(index) + \"]\")\n        else:\n            path.append(node[\"schema_id\"])\n        if \"schema_id\" in node and \"children\" in node:\n            normalize_annotation(\n                node[\"children\"],\n                accumulator,\n                path,\n                True if node[\"category\"] == \"multivalue\" else False,\n                schema,\n                fields_to_db,\n            )\n            path.pop()\n        else:\n            if node[\"content\"]:\n                if node[\"schema_id\"] not in fields_to_db:\n                    path.pop()\n                    continue\n                schema_id_def = get_schema_field_by_id(schema, node[\"schema_id\"])\n                schema_id_type = (\n                    schema_id_def[\"type\"] if schema_id_def[\"type\"] != \"enum\" else schema_id_def.get(\"enum_value_type\")\n                )\n                if not schema_id_type:\n                    schema_id_type = \"string\"\n                if schema_id_type == \"number\":\n                    try:\n                        value = float(node[\"content\"][\"normalized_value\"])\n                    except Exception:\n                        try:\n                            value = float(node[\"content\"][\"value\"])\n                        except Exception:\n                            value = node[\"content\"][\"value\"]\n                else:\n                    value = node[\"content\"][\"value\"]\n\n                groups = re.match(r\"(.+)\\[(\\d+)\\]\", path[len(path) - 2])\n                array_idx = None\n                if groups:\n                    array_idx = int(groups.group(2))\n                if array_idx is not None:\n                    array_path = path[len(path) - 3]\n                    if accumulator.get(array_path) and len(accumulator[array_path]) - 1 >= array_idx:\n                        obj = accumulator[array_path][array_idx]\n                        obj[path[-1]] = value\n                    else:\n                        if accumulator.get(array_path):\n                            accumulator[array_path].append({path[-1]: value})\n                        else:\n                            accumulator[array_path] = []\n                            accumulator[array_path].append({path[-1]: value})\n                else:\n                    accumulator[path[-1]] = value\n            path.pop()\n    return accumulator\n\n\ndef get_schema_field_by_id(content: dict, schema_id: str) -> str:\n    \"\"\"\n    Go over Extraction schema (https://api.elis.rossum.ai/docs/#document-schema) and find the field's definition based on its ID.\n    :param dict: content: schema content\n    :param str: schema_id: the ID of the field to be found\n    :return str: found field or None\n    \"\"\"\n    if not isinstance(content, list):\n        return get_schema_field_by_id([content], schema_id)\n\n    for datapoint in content:\n        if \"id\" in datapoint and datapoint[\"id\"] == schema_id:\n            return datapoint\n        else:\n            if \"children\" in datapoint:\n                datapoint = get_schema_field_by_id(datapoint[\"children\"], schema_id)\n                if datapoint is not None:\n                    return datapoint\n    return None\n\n\ndef remove_existing_objects(documents, collection_name, natural_key, primary_key, keep_first, token, ds_url):\n    for doc in documents:\n        filter_cond = {}\n        for key in natural_key:\n            filter_cond[key] = doc[key]\n        if keep_first:\n            results = find_in_data_storage_collection(collection_name, filter_cond, token, ds_url, {\"created_at\": -1})\n            if len(results[\"result\"]) > 1:\n                oids = []\n                # only want to keep the oldest record if the primary key did not change, otherwise replace them all\n                oldest_record = results[\"result\"][0]\n                for pk in primary_key:\n                    if oldest_record.get(pk, \"\") != doc[pk]:\n                        oids.append({\"_id\": oldest_record[\"_id\"]})\n                        break\n                # get ids of all records sharing the same natural key except the oldest one\n                for res in results[\"result\"][1:]:\n                    oids.append({\"_id\": res[\"_id\"]})\n                filter_cond = {\"$or\": oids}\n                delete_many_data_storage_collection(collection_name, filter_cond, token, ds_url)\n                return True\n            elif len(results[\"result\"]) == 1:\n                return True\n            return False\n        else:\n            delete_many_data_storage_collection(collection_name, filter_cond, token, ds_url)\n            return False\n\n\ndef create_record_in_ds(messages, payload, document, token, aliases, collection_name, ds_url):\n    ts = int(datetime.now().timestamp() * 1000)\n    for doc in document:\n        doc = replace_aliases(doc, aliases)\n        doc[\"annotation_id\"] = payload[\"annotation\"][\"id\"]\n        doc[\"created_at\"] = {\"$date\": {\"$numberLong\": ts}}\n\n    response = insert_many_data_storage_collection(collection_name, document, token, ds_url)\n    if response.status_code != 200:\n        messages.append(\n            create_message(\"warning\", \"Data storage find endpoint returned an error message: \" + response.text, None)\n        )\n    else:\n        messages.append(create_message(\"info\", \"Record(s) inserted\", None))\n    return messages\n\n\ndef insert_many_data_storage_collection(collectionName, document, token, ds_url):\n    payload = {\"collectionName\": collectionName, \"documents\": document}\n    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {token}\"}\n\n    try:\n        req = requests.post(f\"{ds_url}/data/insert_many\", json=payload, headers=headers, timeout=20)\n    except Exception as ex:\n        return str(ex)\n\n    return req\n\n\ndef delete_many_data_storage_collection(collectionName, document, token, ds_url):\n    payload = {\"collectionName\": collectionName, \"filter\": document}\n    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {token}\"}\n\n    try:\n        req = requests.post(f\"{ds_url}/data/delete_many\", json=payload, headers=headers, timeout=20)\n    except Exception as ex:\n        return str(ex)\n\n    return req\n\n\ndef find_in_data_storage_collection(collectionName, query, token, ds_url, sort):\n    payload = {\"collectionName\": collectionName, \"query\": query, \"sort\": sort}\n    header = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {token}\"}\n\n    try:\n        req = requests.post(f\"{ds_url}/data/find\", json=payload, headers=header, timeout=20)\n    except Exception as ex:\n        return str(ex)\n\n    return json.loads(req.text)\n\n\ndef find_by_schema_id(content: dict, schema_id: str) -> tuple:\n    \"\"\"\n    Return datapoints matching a schema id.\n    :param content: annotation content tree (see https://api.elis.rossum.ai/docs/#annotation-data)\n    :param schema_id: field's ID as defined in the extraction schema(see https://api.elis.rossum.ai/docs/#document-schema)\n    :param accumulator: list for accumulating values with the same schema_id (f.e. values from same table column)\n    :return: the list of datapoints matching the schema ID\n    \"\"\"\n    accumulator = []\n    for node in content:\n        if node[\"schema_id\"] == schema_id:\n            accumulator.append(node)\n        elif \"children\" in node:\n            accumulator.extend(find_by_schema_id(node[\"children\"], schema_id))\n\n    return accumulator\n\n\ndef create_replace_operation(datapoint, new_value):\n    \"\"\"\n    Create and operation to replace the value of the datapoint with a new value.\n    :param datapoint: content of the datapoint\n    :param new_value: new value of the datapoint\n    :return: dict with replace operation definition (see https://api.elis.rossum.ai/docs/#annotation-content-event-response-format)\n    \"\"\"\n    return {\n        \"op\": \"replace\",\n        \"id\": datapoint[\"id\"],\n        \"value\": {\n            \"content\": {\n                \"value\": new_value,\n            }\n        },\n    }\n\n\ndef find_by_datapoint_id(content, datapoint_id):\n    \"\"\"\n    Find specific datapoint by a datapoint ID.\n    :param content: annotation content tree (see https://api.elis.rossum.ai/docs/#annotation-data)\n    :param datapoint_id: ID of a specific datapoint\n    :return: dict representing the found field\n    \"\"\"\n    for node in content:\n        if node[\"id\"] == datapoint_id:\n            return node\n\n        elif \"children\" in node:\n            result = find_by_datapoint_id(node[\"children\"], datapoint_id)\n\n            if result:\n                return result\n            else:\n                continue\n\n    return None\n\n\ndef create_message(message_type, message_content, datapoint_id=None):\n    \"\"\"\n    Create a message which will be shown to the user\n    :param message_type: type of the message, any of {info|warning|error}. Errors prevent confirmation in the UI.\n    :param message_content: message shown to the user\n    :param datapoint_id: id of the datapoint where the message will appear (None for \"global\" messages).\n    :return: dict with the message definition (see https://api.elis.rossum.ai/docs/#annotation-content-event-response-format)\n    \"\"\"\n    return {\n        \"content\": message_content,\n        \"type\": message_type,\n        \"id\": datapoint_id,\n    }",
    "third_party_library_pack": "default",
    "memory_size_mb": 256
  },
  "test": {},
  "sideload": [
    "schemas"
  ],
  "settings_schema": null,
  "secrets_schema": {
    "type": "object",
    "additionalProperties": {
      "type": "string"
    }
  },
  "token_owner": "https://us.api.rossum.ai/v1/users/383208",
  "extension_source": "custom",
  "guide": null,
  "read_more_url": null,
  "extension_image_url": null,
  "token_lifetime_s": null,
  "hook_template": null,
  "created_by": "https://us.api.rossum.ai/v1/users/354857",
  "created_at": "2025-03-21T15:39:27.220208Z",
  "modified_by": "https://us.api.rossum.ai/v1/users/354857",
  "modified_at": "2025-03-21T15:39:46.699594Z"
}